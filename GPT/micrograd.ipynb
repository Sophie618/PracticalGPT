{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 3*x**2-4*x+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs=np.arange(-5,5,0.25)#从-5到5(不含)步长0.25\n",
    "ys=f(xs)\n",
    "plt.plot(xs,ys);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "h=0.000001\n",
    "x=-3\n",
    "(f(x+h)-f(x))/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h=0.0001\n",
    "\n",
    "a=2.0\n",
    "b=-3.0\n",
    "c=10.0\n",
    "\n",
    "d1=a*b+c\n",
    "b+=h\n",
    "d2=a*b+c\n",
    "\n",
    "print('d1',d1)\n",
    "print('d2',d2)\n",
    "print('slope',(d1-d2)/h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "\n",
    "    def __init__(self,data,_children=(),_op='',label=''):#初始化class,children是一个空tuple\n",
    "        self.data=data\n",
    "        self.grad=0.0\n",
    "        self._backward=lambda:None#默认是空函数,不做任何操作\n",
    "        self._prev=set(_children)#把元组转换为集合\n",
    "        self._op=_op\n",
    "        self.label=label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"#wrapper函数提供一个更加美观的打印结果\n",
    "    \n",
    "    def __add__(self,other):\n",
    "        other=other if isinstance(other,Value) else Value(other)#若other是Value的实例直接返回，若不是则将其包装为Value类型\n",
    "        out=Value(self.data+other.data,(self,other),'+')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad+=1.0*out.grad\n",
    "            other.grad+=1.0*out.grad\n",
    "        out._backward=_backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def __neg__(self):#-self\n",
    "        return self*-1\n",
    "    \n",
    "    def __sub__(self,other):#self-other\n",
    "        return self+(-other)\n",
    "    \n",
    "    def __mul__(self,other):\n",
    "        other=other if isinstance(other,Value) else Value(other)\n",
    "        out=Value(self.data*other.data,(self,other),'*')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad+=other.data*out.grad\n",
    "            other.grad+=self.data*out.grad\n",
    "        out._backward=_backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def __pow__(self,other):\n",
    "        assert isinstance(other,(float,int))#现在仅支持整数型或浮点型\n",
    "        out=Value(self.data**other,(self,),f'**{other}')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad+=other*self.data**(other-1)*out.grad#other就是数字，不需要.data\n",
    "        out._backward=_backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def tanh(self):\n",
    "        x=self.data\n",
    "        t=(math.exp(2*x)-1)/(math.exp(2*x)+1)\n",
    "        out=Value(t,(self,),'tanh')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad+=(1-t**2) * out.grad\n",
    "        out._backward=_backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def __rmul__(self,other):# other * self\n",
    "        return self*other\n",
    "    \n",
    "    def __truediv__(self,other):#self / other\n",
    "        return self*other**-1\n",
    "    \n",
    "    def exp(self):\n",
    "        x=self.data\n",
    "        out=Value(math.exp(x),(self,),'exp')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad+=out.data*out.grad\n",
    "        out._backward=_backward\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self):\n",
    "        #拓扑排序topological sort\n",
    "        topo=[]\n",
    "        visited=set()#避免重复遍历同一个节点\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)#visited 集合保证了 topo 里没有重复节点\n",
    "        build_topo(self)\n",
    "\n",
    "        self.grad=1.0#若不初始化为1，grad仍旧保持0则反向传播的时候只要相乘前面的grad就全部为零了\n",
    "        for node in reversed(topo):\n",
    "            node._backward()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=Value(2.0,label='a')\n",
    "a.exp()\n",
    "b=Value(-3.0,label='b')\n",
    "a**b.data\n",
    "\n",
    "# c=Value(10.0,label='c')\n",
    "# e=a*b; e.label='e'\n",
    "# d=e+c;d.label='d'\n",
    "# f=Value(-2.0,label='f')\n",
    "# L=f*d;L.label='L'\n",
    "#(a.__mul__(b)).__add__(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph #画计算图\n",
    "\n",
    "def trace(root):\n",
    "    #构建计算图中的所有边和节点\n",
    "    nodes,edges=set(),set()\n",
    "    def build(v):\n",
    "        if v not in nodes:\n",
    "            nodes.add(v)\n",
    "            for child in v._prev:\n",
    "                edges.add((child,v))\n",
    "                build(child)\n",
    "    build(root)\n",
    "    return nodes,edges\n",
    "\n",
    "def draw_dot(root):\n",
    "    dot=Digraph(format='svg',graph_attr={'rankdir':'LR'})#LR:left to right\n",
    "    nodes,edges=trace(root)\n",
    "    for n in nodes:\n",
    "        uid=str(id(n))\n",
    "        dot.node(name=uid,label=\"{%s|data %.4f|grad %.4f}\"%(n.label,n.data,n.grad),shape='record')\n",
    "        if n._op:\n",
    "            dot.node(name=uid+n._op,label=n._op)# 创建操作节点\n",
    "            dot.edge(uid+n._op,uid)#操作节点 → 数值节点\n",
    "\n",
    "    for n1,n2 in edges:\n",
    "        dot.edge(str(id(n1)),str(id(n2))+n2._op)# 输入节点→操作节点\n",
    "\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs x1,x2\n",
    "x1=Value(2.0,label='x1')\n",
    "x2=Value(0.0,label='x2')\n",
    "#weights w1,w2\n",
    "w1=Value(-3.0,label='w1')\n",
    "w2=Value(1.0,label='w2')\n",
    "#bias of the neuron\n",
    "b=Value(6.8813735870195432,label='b')\n",
    "#x1*w1 +x2*w2 + b\n",
    "x1w1=x1*w1;x1w1.label='x1*w1'\n",
    "x2w2=x2*w2;x2w2.label='x2*w2'\n",
    "x1w1x2w2=x1w1+x2w2;x1w1x2w2.label='x1*w1 + x2*w2'\n",
    "n=x1w1x2w2+b;n.label='n'\n",
    "#---\n",
    "e=(2*n).exp();e.label='e'\n",
    "o=(e-1)/(e+1)\n",
    "#---\n",
    "o.label='o'\n",
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x1=torch.tensor([2.0]).double();x1.requires_grad=True#由于是叶节点默认不计算grad，这里专门都设置为需要计算\n",
    "x2=torch.tensor([0.0]).double();x2.requires_grad=True\n",
    "w1=torch.tensor([-3.0]).double();w1.requires_grad=True\n",
    "w2=torch.tensor([1.0]).double();w2.requires_grad=True\n",
    "b=torch.tensor([6.8813735870195432]).double();b.requires_grad=True\n",
    "n=x1*w1+x2*w2+b\n",
    "o=torch.tanh(n)\n",
    "\n",
    "print(o.item())#去除张量结构\n",
    "o.backward()\n",
    "\n",
    "print(\"---\")\n",
    "print('x1',x1.grad.item())\n",
    "print('w1',w1.grad.item())\n",
    "print('x2',x2.grad)\n",
    "print('w2',w2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([2.0]).double().dtype #PyTorch默认float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:#define a Neuron\n",
    "    def __init__(self,nin):#nin是神经元接收的输入数量\n",
    "        self.w=[Value(np.random.uniform(-1,1)) for _ in range(nin)]#创建数组，大小为nin数值在-1到1间\n",
    "        self.b=Value(np.random.uniform(-1,1))\n",
    "\n",
    "    def __call__(self,x):\n",
    "        # w * x + b\n",
    "        act=sum((wi*xi for wi,xi in zip(self.w,x)),self.b)#get an activation得到激活值,初始值为self.b\n",
    "        out=act.tanh()\n",
    "        return out\n",
    "    \n",
    "class Layer:#每层含有多个神经元\n",
    "    def __init__(self,nin, nout):\n",
    "        self.neurons=[Neuron(nin) for _ in range(nout)] \n",
    "\n",
    "    def __call__(self,x):\n",
    "        outs=[n(x) for n in self.neurons]\n",
    "        return outs\n",
    "    \n",
    "x=[2.0,3.0]\n",
    "n=Neuron(2)# 2. 创建神经元（2个输入）n = Neuron(2)\n",
    "n(x)# ↓ 等价于n.__call__(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AILearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
